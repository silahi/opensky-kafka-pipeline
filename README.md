# âœˆï¸ OpenSky â†’ Kafka â†’ Postgres Pipeline

## ğŸ“Œ Description
Ce projet collecte en temps rÃ©el des donnÃ©es de vol depuis lâ€™API **OpenSky Network**, 
les publie dans **Apache Kafka** (Confluent Cloud), puis les synchronise dans une base **Postgres** (hÃ©bergÃ©e sur Neon).

Lâ€™objectif est de construire une pipeline **data engineering** moderne, inspirÃ©e de cas rÃ©els (monitoring aÃ©ronautique pour lâ€™ASECNA).

---

## ğŸ—ï¸ Architecture

# Flux de donnÃ©es OpenSky â†’ Kafka â†’ Postgres


- **Producer Python** : rÃ©cupÃ¨re les donnÃ©es OpenSky et les envoie vers Kafka.  
- **Kafka Confluent Cloud** : ingÃ¨re les messages Avro (key + value) et versionne les schÃ©mas via Schema Registry.  
- **Postgres (Neon)** : stockage persistant via Kafka Connect Sink.  
- **Visualisation** (optionnelle) : Kibana, Superset ou Grafana pour explorer les donnÃ©es.

---

## ğŸ—‚ï¸ Structure du projet

 `opensky-kafka-pipeline`

```text
opensky-kafka-pipeline/
â”‚â”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ pipeline.yml        # GitHub Actions workflow (scheduler)
â”‚
â”‚â”€â”€ config/
â”‚   â”œâ”€â”€ confluent_config.json   # Credentials Confluent Cloud + Kafka topic
â”‚   â””â”€â”€ neon_config.json        # Optionnel si besoin Postgres direct
â”‚
â”‚â”€â”€ src/
â”‚   â”œâ”€â”€ producer.py             # Code du producer Kafka
â”‚   â”œâ”€â”€ fetch_opensky.py        # Fonction pour requÃªter l'API OpenSky
â”‚   â”œâ”€â”€ utils.py                # Fonctions utilitaires (log, retryâ€¦)
â”‚   â””â”€â”€ __init__.py
â”‚
â”‚â”€â”€ requirements.txt            # DÃ©pendances Python
â”‚â”€â”€ README.md                   # Documentation projet
â”‚â”€â”€ LICENSE                     # Licence (ex: MIT)
```



---

## ğŸš€ Installation locale

1. Cloner le repository :
```bash
git clone https://github.com/<ton-repo>/opensky-kafka-pipeline.git
cd opensky-kafka-pipeline
```
2. Installer les dÃ©pendances :
```bash
pip install -r requirements.txt
```
3. CrÃ©er le fichier config/confluent_config.json manuellement (si test local) :
```json
{
  "bootstrap.servers": "<TON_BOOTSTRAP_SERVERS>",
  "security.protocol": "SASL_SSL",
  "sasl.mechanism": "PLAIN",
  "sasl.username": "<TON_USERNAME>",
  "sasl.password": "<TON_PASSWORD>",
  "schema.registry.url": "<TON_SCHEMA_REGISTRY_URL>",
  "basic.auth.user.info": "<TON_SCHEMA_AUTH>",
  "topic": "aircraft-states"
}
```
## â–¶ï¸ Lancer le producer localement
```bash
python src/producer.py
```
Le producer rÃ©cupÃ¨re les donnÃ©es OpenSky toutes les 5 minutes et les publie sur Kafka.


-----
## â˜ï¸ Scheduler GitHub Actions

Le pipeline est automatisÃ© avec GitHub Actions et sÃ©curisÃ© :

- Le fichier config/confluent_config.json est gÃ©nÃ©rÃ© Ã  lâ€™exÃ©cution Ã  partir des Secrets GitHub.
- Pas de credentials en clair dans le repo.
- Planification via cron (ex. toutes les 15 minutes).

### Exemple de workflow **.github/workflows/producer.yml**
```yaml
name: Run Kafka Producer

on:
  schedule:
    - cron: "*/15 * * * *"
  workflow_dispatch:

jobs:
  run-producer:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Create confluent config from secrets
        run: |
          mkdir -p config
          cat > config/confluent_config.json <<EOL
          {
            "bootstrap.servers": "${{ secrets.BOOTSTRAP_SERVERS }}",
            "security.protocol": "SASL_SSL",
            "sasl.mechanism": "PLAIN",
            "sasl.username": "${{ secrets.SASL_USERNAME }}",
            "sasl.password": "${{ secrets.SASL_PASSWORD }}",
            "schema.registry.url": "${{ secrets.SCHEMA_REGISTRY_URL }}",
            "basic.auth.user.info": "${{ secrets.SCHEMA_REGISTRY_AUTH }}",
            "topic": "${{ secrets.TOPIC }}"
          }
          EOL

      - name: Run Kafka Producer
        run: python src/producer.py
```
## ğŸ”¹ GitHub Secrets nÃ©cessaires

- BOOTSTRAP_SERVERS
- SASL_USERNAME
- SASL_PASSWORD
- SCHEMA_REGISTRY_URL
- SCHEMA_REGISTRY_AUTH
- TOPIC

## ğŸ“Š Cas dâ€™usage ASECNA

- DÃ©tection des vols entrants dans une rÃ©gion donnÃ©e.
- Alerte sur trajectoires anormales ou perte de signal.
- Archivage et analyse du trafic aÃ©rien en temps rÃ©el.

